{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "collapsed": true,
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Inspiration 1: https://www.kaggle.com/tunguz/logistic-regression-with-words-and-char-n-grams/code\n# Inspiration 2: https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nimport re, string\nimport time\nfrom scipy.sparse import hstack\nfrom scipy.special import logit, expit\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7a9def5093420ee0cb33e3c4dbdb284af0e763b9",
        "collapsed": true,
        "_cell_guid": "890ecc79-0b1e-422a-beab-c20b5b588ae4",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Functions\ndef tokenize(s): return re_tok.sub(r' \\1 ', s).split()\n\n\ndef pr(y_i, y, x):\n    p = x[y==y_i].sum(0)\n    return (p+1) / ((y==y_i).sum()+1)\n\n\ndef get_mdl(y,x, c0 = 4):\n    y = y.values\n    r = np.log(pr(1,y,x) / pr(0,y,x))\n    m = LogisticRegression(C= c0, dual=True)\n    x_nb = x.multiply(r)\n    return m.fit(x_nb, y), r\n\n\ndef multi_roc_auc_score(y_true, y_pred):\n    assert y_true.shape == y_pred.shape\n    columns = y_true.shape[1]\n    column_losses = []\n    for i in range(0, columns):\n        column_losses.append(roc_auc_score(y_true[:, i], y_pred[:, i]))\n    return np.array(column_losses).mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "648a414512e100686384f54a335f279ffb60dc25",
        "collapsed": true,
        "_cell_guid": "2e91fb5c-aa54-4509-adf1-02100d4d59e3",
        "trusted": false
      },
      "cell_type": "code",
      "source": "model_type = 'lrchar'\ntodate = time.strftime(\"%d%m\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1ce08d3aa6e6582ae66286a7bb870c23c133ca86",
        "_cell_guid": "10154f60-38e2-4ba2-ac3f-337cdabcc677"
      },
      "cell_type": "markdown",
      "source": "# Data"
    },
    {
      "metadata": {
        "_uuid": "a81bbe05d6bb731e198b6f3c753620532be4d600",
        "collapsed": true,
        "_cell_guid": "ad29a64e-d548-4b14-8c19-5a5adbab3e74",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# read data\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nsubm = pd.read_csv('../input/sample_submission.csv')\n\nid_train = train['id'].copy()\nid_test = test['id'].copy()\n\n# add empty label for None\nlabel_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\ntrain['none'] = 1-train[label_cols].max(axis=1)\n# fill missing values\nCOMMENT = 'comment_text'\ntrain[COMMENT].fillna(\"unknown\", inplace=True)\ntest[COMMENT].fillna(\"unknown\", inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "375e268097baecafa125fc7fe8c879d40a25efa8",
        "collapsed": true,
        "_cell_guid": "f2b78b34-b627-4788-a0f1-2571eab44e3b",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Tf-idf\n# prepare tokenizer\nre_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n\n# create sparse matrices\nn = train.shape[0]\n#vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,  min_df=3, max_df=0.9, strip_accents='unicode',\n#                      use_idf=1, smooth_idf=1, sublinear_tf=1 )\n\nword_vectorizer = TfidfVectorizer(\n    tokenizer=tokenize,\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word', \n    min_df = 5,\n    token_pattern=r'\\w{1,}',\n    ngram_range=(1, 3))\n#     ,\n#     max_features=250000)\n\nall1 = pd.concat([train[COMMENT], test[COMMENT]])\nword_vectorizer.fit(all1)\nxtrain1 = word_vectorizer.transform(train[COMMENT])\nxtest1 = word_vectorizer.transform(test[COMMENT])\n\nchar_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='char',\n    min_df = 3,\n    ngram_range=(1, 6))\n#     ,\n#     max_features=250000)\n\nall1 = pd.concat([train[COMMENT], test[COMMENT]])\nchar_vectorizer.fit(all1)\n\nxtrain2 = char_vectorizer.transform(train[COMMENT])\nxtest2 = char_vectorizer.transform(test[COMMENT])\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bfdb92b679fed1e718a8a3b6e4d61caa8f7aa2ee",
        "_cell_guid": "f948babf-3396-4aa9-91c8-adde0c62ff0a"
      },
      "cell_type": "markdown",
      "source": "# Model"
    },
    {
      "metadata": {
        "_uuid": "fc94a43d0a5a0613d3bdbce0c15c25454573eac6",
        "collapsed": true,
        "_cell_guid": "17517658-06fa-4437-ab4d-9e0d011e7753",
        "trusted": false
      },
      "cell_type": "code",
      "source": "nfolds = 5\nxseed = 29\ncval = 4\n\n# data setup\nxtrain = hstack([xtrain1, xtrain2], format='csr')\nxtest = hstack([xtest1,xtest2], format='csr')\nytrain = np.array(train[label_cols].copy())\n\n# stratified split\nskf = StratifiedKFold(n_splits= nfolds, random_state= xseed)\n\n# storage structures for prval / prfull\npredval = np.zeros((xtrain.shape[0], len(label_cols)))\npredfull = np.zeros((xtest.shape[0], len(label_cols)))\nscoremat = np.zeros((nfolds,len(label_cols) ))\nscore_vec = np.zeros((len(label_cols),1))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c6b3c62063bda4ed1a8a6b8845454278766929fd",
        "collapsed": true,
        "_cell_guid": "a8d92c33-64f8-4302-bf49-e38712fd6b8f",
        "trusted": false
      },
      "cell_type": "code",
      "source": "for (lab_ind,lab) in enumerate(label_cols):   \n    y = train[lab].copy()\n    print('label:' + str(lab_ind))\n    for (f, (train_index, test_index)) in enumerate(skf.split(xtrain, y)):\n        # split \n        x0, x1 = xtrain[train_index], xtrain[test_index]\n        y0, y1 = y[train_index], y[test_index]    \n        # fit model for prval\n        m,r = get_mdl(y0,x0, c0 = cval)\n        predval[test_index,lab_ind] = m.predict_proba(x1.multiply(r))[:,1]\n        scoremat[f,lab_ind] = roc_auc_score(y1,predval[test_index,lab_ind])\n        # fit model full\n        m,r = get_mdl(y,xtrain, c0 = cval)\n        predfull[:,lab_ind] += m.predict_proba(xtest.multiply(r))[:,1]\n        print('fit:'+ str(lab) + ' fold:' + str(f) + ' score:%.6f' %(scoremat[f,lab_ind]))\n#    break\npredfull /= nfolds ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b14075b625915e7dc8d6b8eff44c79d4b075065d",
        "collapsed": true,
        "_cell_guid": "0a45a046-7e09-40df-b9a1-116397cf4d09",
        "trusted": false
      },
      "cell_type": "code",
      "source": "score_vec = np.zeros((len(label_cols),1))\nfor ii in range(len(label_cols)):\n    score_vec[ii] = roc_auc_score(ymat[:,ii], predval[:,ii])\nprint(score_vec.mean())\nprint(multi_roc_auc_score(ymat, predval))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "586123023ff44c843d2c765475b344a1d5be5922",
        "_cell_guid": "0b575f63-b40d-448a-8542-e4d753bd7d10"
      },
      "cell_type": "markdown",
      "source": "# Store resultss"
    },
    {
      "metadata": {
        "_uuid": "1eaae93a1bd8569eeefc61c5b7207cccb526db2f",
        "collapsed": true,
        "_cell_guid": "65f0fee6-bad7-4eef-b5ca-0f3b96cad666",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# store prval\nprval = pd.DataFrame(predval)\nprval.columns = label_cols\nprval['id'] = id_train\nprval.to_csv('prval_'+model_type+'x'+str(cval)+'f'+str(nfolds)+'_'+todate+'.csv', index= False)\n\n# store prfull\nprfull = pd.DataFrame(predfull)\nprfull.columns = label_cols\nprfull['id'] = id_test\nprfull.to_csv('prfull_'+model_type+'x'+str(cval)+'f'+str(nfolds)+'_'+todate+'.csv', index= False)\n\n# store submission\nsubmid = pd.DataFrame({'id': subm[\"id\"]})\nsubmission = pd.concat([submid, pd.DataFrame(prfull, columns = label_cols)], axis=1)\nsubmission.to_csv('sub_'+model_type+'x'+str(cval)+'f'+str(nfolds)+'_'+todate+'.csv', index= False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a7f182e6d38bf01d2ab905c839ef5fe635c89412",
        "_cell_guid": "192daff3-4d61-4c9b-9ca9-a7c2840947a3"
      },
      "cell_type": "markdown",
      "source": ""
    },
    {
      "metadata": {
        "_uuid": "47fcbff298a283564216632bac24f1bfba81c28b",
        "_cell_guid": "d353d366-049e-4b6a-b13f-261d8f1852bc"
      },
      "cell_type": "markdown",
      "source": ""
    },
    {
      "metadata": {
        "_uuid": "b3612a10b1146a4bbab18d465d2cc52e7ec1cfd1",
        "_cell_guid": "e4773030-4e38-4345-90fe-0187175e70fa"
      },
      "cell_type": "markdown",
      "source": ""
    },
    {
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "collapsed": true,
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0"
      },
      "cell_type": "markdown",
      "source": ""
    },
    {
      "metadata": {
        "_uuid": "5b73a04728cd61f0aefb38eca18b1d50116d8630",
        "_cell_guid": "102a72e7-ed1f-43db-87b7-4aa00d1899d5"
      },
      "cell_type": "markdown",
      "source": ""
    },
    {
      "metadata": {
        "_uuid": "5a86027bcd41e4c5898e284cf32afb3f722df3e1",
        "_cell_guid": "a9c3c701-b750-4ae2-a9e6-7b8a3c68096c"
      },
      "cell_type": "markdown",
      "source": ""
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "file_extension": ".py",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}