{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "59afa460-67bb-4083-8f64-4e8bdc7d688e",
        "_uuid": "e1f3247609398721b4c6b37da205be55e341b899"
      },
      "cell_type": "markdown",
      "source": "This is a basic LogisticRegression model trained using the data from https://www.kaggle.com/eoveson/convai-datasets-baseline-models\n\nThe baseline model in that kernal is tuned a little to get the data for this kernal This kernal scored 0.044 in the LB"
    },
    {
      "metadata": {
        "_cell_guid": "eb9acbb1-40db-4a60-9c00-7e1134408cb1",
        "_uuid": "7e97dad72af19207237cb816bc898ca5818f4389",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom scipy import sparse\n# set stopwords\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "bb967e03-d30b-46ec-b9d2-c0f5d4c0ee68",
        "_uuid": "97b399586c43626b73bc77b50e58b952d86ea8da",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "train = pd.read_csv('../input/dataset/train_with_convai.csv')\ntest = pd.read_csv('../input/dataset/test_with_convai.csv')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1eebb207-607e-4985-908e-9848888808b1",
        "_uuid": "3e90295dde0dd25158ea9e3464165aa8ea62fd1c",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "feats_to_concat = ['comment_text', 'toxic_level', 'attack', 'aggression']\n# combining test and train\nalldata = pd.concat([train[feats_to_concat], test[feats_to_concat]], axis=0)\nalldata.comment_text.fillna('unknown', inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "88a8e609-b287-4a7e-b72d-5dcac6f4a55f",
        "_uuid": "741273ee4b5122a37d978708ba29e16879e5b33f",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "vect_words = TfidfVectorizer(max_features=50000, analyzer='word', ngram_range=(1, 1))\nvect_chars = TfidfVectorizer(max_features=20000, analyzer='char', ngram_range=(1, 3))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "6db22032-8e99-4848-8978-be7c68a1e936",
        "_uuid": "cf10b99072cef22bf87ee92c9aa51f035a26e893",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "all_words = vect_words.fit_transform(alldata.comment_text)\nall_chars = vect_chars.fit_transform(alldata.comment_text)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "8f42e0d7-5938-4bb0-beb7-7ddf9f85685d",
        "_uuid": "d074b6b6c5271f462c129c534980c5a0d287599f",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_new = train\ntest_new = test",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "c068c9bb-bf28-4342-aa71-e575c6d93788",
        "_uuid": "09975f14757c51e19876dab638a39671dfd555e4",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_words = all_words[:len(train_new)]\ntest_words = all_words[len(train_new):]\n\ntrain_chars = all_chars[:len(train_new)]\ntest_chars = all_chars[len(train_new):]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "5d55e152-e1cb-4cf0-aa41-e3eec5850b3a",
        "_uuid": "0338f2d0b8f09c751f97afebf1cf8e77d8a10fe3",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "feats = ['toxic_level', 'attack']\n# make sparse matrix with needed data for train and test\ntrain_feats = sparse.hstack([train_words, train_chars, alldata[feats][:len(train_new)]])\ntest_feats = sparse.hstack([test_words, test_chars, alldata[feats][len(train_new):]])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "350aad79-ee6f-44bc-9d85-4e9652956bd3",
        "_uuid": "da2082c68a367369fac28ddc09eec2e5b6c718bb",
        "scrolled": false,
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "col = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n\nonly_col = ['toxic']\n\npreds = np.zeros((test_new.shape[0], len(col)))\n\nfor i, j in enumerate(col):\n    print('===Fit '+j)\n    \n    model = LogisticRegression(C=4.0, solver='sag')\n    print('Fitting model')\n    model.fit(train_feats, train_new[j])\n      \n    print('Predicting on test')\n    preds[:,i] = model.predict_proba(test_feats)[:,1]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "9d84b909-d93b-4778-b432-701f65a73d3c",
        "_uuid": "3605ca797e6d5e4d05ac2c63d70766c23d2a8cf1",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "subm = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv')\n\nsubmid = pd.DataFrame({'id': subm[\"id\"]})\nsubmission = pd.concat([submid, pd.DataFrame(preds, columns = col)], axis=1)\nsubmission.to_csv('feat_lr_2cols.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "6d350714-1262-4f91-af11-a7f95750ec84",
        "_uuid": "be385cfe2683246d05dc872d7b09cb4608b73337",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}